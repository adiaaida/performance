#!/usr/bin/env python3

from argparse import ArgumentParser
from datetime import datetime
from itertools import chain
from os import path
from sys import exit
from traceback import format_exc

from benchview.console import write
from benchview.format.helpers import get_timestamp_format
from benchview.format.helpers import write_object_as_json
from benchview.format.JSONFormat import Build
from benchview.format.JSONFormat import Configuration
from benchview.format.JSONFormat import MachineData
from benchview.format.JSONFormat import Submission
from benchview.format.JSONFormat import Run
from benchview.format.JSONFormat import Test
from benchview.format.JSONFormat import get_valid_submission_types
from benchview.format.JSONReaders import read_build
from benchview.format.JSONReaders import read_machinedata
from benchview.format.JSONReaders import read_submission_metadata
from benchview.format.JSONReaders import read_tests_from_json
from benchview.utils.common import get_script_directory
from benchview.utils.common import is_supported_version


def get_argument_parser() -> dict:
    parser = ArgumentParser(
        description='Generates a JSON serialized BenchView Submission object.',
        allow_abbrev=False
    )

    # Input/Output files.
    parser.add_argument(
        'infile',
        metavar = '<Input "tests.json" file name>',
        help = 'A list of JSON files containing test results as generated by "measurement.py".',
        nargs = '+'
    )

    parser.add_argument(
        '--metadata',
        help = 'A JSON file containing metadata as generated by "submission-metadata.py".',
        required = True
    )

    parser.add_argument(
        '--machine-data',
        help = 'A JSON file containing the machine data generated by "machinedata.py".',
        required = True
    )

    parser.add_argument(
        '--build',
        help = 'A JSON file containing the build information generated by "build.py".',
        required = True
    )

    parser.add_argument(
        '-o',
        '--outfile',
        metavar = '<Output json file name>',
        help = 'The file path to write to (If not specfied, defaults to "submission.json").',
        required = False,
        default = 'submission.json'
    )

    # Run information.
    parser.add_argument(
        '-arch',
        '--architecture',
        help = 'The architecture of the measurements included in the submission.',
        required = True
    )

    parser.add_argument(
        '--config-name',
        help = 'User facing configuration display name.',
        required = True
    )

    parser.add_argument(
        '--config',
        metavar = ('key', 'value'),
        action = 'append',
        help = 'A configuration property defined as a {key:value} pair.',
        required = True,
        nargs = 2
    )

    parser.add_argument(
        '--machinepool',
        help = 'A logical name that groups all the test results into a single **machine**.',
        required = False
    )

    parser.add_argument(
        '--group',
        help = 'Category to distinguish different batches of uploads.',
        required = True
    )

    parser.add_argument(
        '--type',
        help = '.',
        required = True,
        choices = get_valid_submission_types(),
        type = str.casefold
    )

    return vars(parser.parse_args())

def main() -> int:
    try:
        if not is_supported_version():
            write.error("You need to use Python 3.5 or newer.")
            return 1

        args = get_argument_parser()

        submission = read_submission_metadata(args['metadata'])

        tests = []
        for infile in args['infile']:
            tests += read_tests_from_json(infile)

        architecture = args['architecture']
        build = read_build(args['build'])
        machine_data = read_machinedata(args['machine_data'])
        machinepool = args['machinepool']

        properties = list(chain(*args['config']))
        i = iter(properties)
        properties = dict(zip(i, i))
        configuration = Configuration(args['config_name'], properties)

        run = Run(
            architecture,
            build,
            configuration,
            args['group'],
            machine_data.machine,
            machinepool,
            machine_data.os,
            tests,
            args['type'])

        submission.runs.append(run)

        scriptDirectory = get_script_directory(__file__)
        schemaFileName = path.join(scriptDirectory, '..', 'schemas', 'submission.json')
        write_object_as_json(args['outfile'], submission, schemaFileName)
    except Exception as ex:
        write.error('{0}: {1}'.format(type(ex), str(ex)))
        write.error(format_exc())
        return 1

    return 0

if __name__ == "__main__":
    exit(main())
